{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psychrolib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Fault</th>\n",
       "      <th>CDWL_CW_FLOW</th>\n",
       "      <th>CDWL_PM_POW_1</th>\n",
       "      <th>CDWL_PM_POW_2</th>\n",
       "      <th>CDWL_PM_POW_3</th>\n",
       "      <th>CDWL_RW_TEMP</th>\n",
       "      <th>CDWL_SW_TEMP</th>\n",
       "      <th>CHL_CD_FLOW_1</th>\n",
       "      <th>CHL_CD_FLOW_2</th>\n",
       "      <th>...</th>\n",
       "      <th>CWL_SEC_PM_POW_2</th>\n",
       "      <th>CWL_SEC_PM_SPD_1</th>\n",
       "      <th>CWL_SEC_PM_SPD_2</th>\n",
       "      <th>CWL_SEC_PM_STA_1</th>\n",
       "      <th>CWL_SEC_PM_STA_2</th>\n",
       "      <th>CWL_SEC_RW_TEMP</th>\n",
       "      <th>CWL_SEC_SW_TEMP</th>\n",
       "      <th>OA_TEMP</th>\n",
       "      <th>OA_TEMP_WB</th>\n",
       "      <th>TWV_CTRL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>N</td>\n",
       "      <td>1126.6614</td>\n",
       "      <td>46.084146</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>69.188995</td>\n",
       "      <td>61.984875</td>\n",
       "      <td>1126.6584</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.816963</td>\n",
       "      <td>57.150177</td>\n",
       "      <td>9.070051</td>\n",
       "      <td>10.355011</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2018-01-01 02:00:00</td>\n",
       "      <td>N</td>\n",
       "      <td>1126.6614</td>\n",
       "      <td>28.012340</td>\n",
       "      <td>4.737310e-24</td>\n",
       "      <td>3.340467e-32</td>\n",
       "      <td>63.610245</td>\n",
       "      <td>60.103905</td>\n",
       "      <td>1126.6584</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>...</td>\n",
       "      <td>51.716137</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.060660</td>\n",
       "      <td>56.109330</td>\n",
       "      <td>9.612884</td>\n",
       "      <td>10.925037</td>\n",
       "      <td>0.000902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2018-01-01 03:00:00</td>\n",
       "      <td>N</td>\n",
       "      <td>1126.6614</td>\n",
       "      <td>8.838832</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>60.941230</td>\n",
       "      <td>59.984650</td>\n",
       "      <td>1126.6584</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>...</td>\n",
       "      <td>51.716137</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.338280</td>\n",
       "      <td>54.349762</td>\n",
       "      <td>10.632746</td>\n",
       "      <td>12.002028</td>\n",
       "      <td>0.031300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2018-01-01 04:00:00</td>\n",
       "      <td>N</td>\n",
       "      <td>1126.6614</td>\n",
       "      <td>7.700014</td>\n",
       "      <td>1.897874e-22</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>59.942516</td>\n",
       "      <td>59.670662</td>\n",
       "      <td>1126.6584</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>...</td>\n",
       "      <td>48.771226</td>\n",
       "      <td>0.982353</td>\n",
       "      <td>0.982353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.982270</td>\n",
       "      <td>53.984024</td>\n",
       "      <td>10.649775</td>\n",
       "      <td>12.019989</td>\n",
       "      <td>0.394997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>2018-01-01 05:00:00</td>\n",
       "      <td>N</td>\n",
       "      <td>1126.6614</td>\n",
       "      <td>7.622777</td>\n",
       "      <td>1.744471e-28</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>59.875774</td>\n",
       "      <td>59.754925</td>\n",
       "      <td>1126.6584</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>...</td>\n",
       "      <td>11.441535</td>\n",
       "      <td>0.619520</td>\n",
       "      <td>0.619520</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.952988</td>\n",
       "      <td>53.952496</td>\n",
       "      <td>11.487482</td>\n",
       "      <td>12.904993</td>\n",
       "      <td>0.610889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Datetime Fault  CDWL_CW_FLOW  CDWL_PM_POW_1  CDWL_PM_POW_2  \\\n",
       "0    2018-01-01 01:00:00     N     1126.6614      46.084146   0.000000e+00   \n",
       "60   2018-01-01 02:00:00     N     1126.6614      28.012340   4.737310e-24   \n",
       "120  2018-01-01 03:00:00     N     1126.6614       8.838832   0.000000e+00   \n",
       "180  2018-01-01 04:00:00     N     1126.6614       7.700014   1.897874e-22   \n",
       "240  2018-01-01 05:00:00     N     1126.6614       7.622777   1.744471e-28   \n",
       "\n",
       "     CDWL_PM_POW_3  CDWL_RW_TEMP  CDWL_SW_TEMP  CHL_CD_FLOW_1  CHL_CD_FLOW_2  \\\n",
       "0     0.000000e+00     69.188995     61.984875      1126.6584       0.001502   \n",
       "60    3.340467e-32     63.610245     60.103905      1126.6584       0.001502   \n",
       "120   0.000000e+00     60.941230     59.984650      1126.6584       0.001502   \n",
       "180   0.000000e+00     59.942516     59.670662      1126.6584       0.001502   \n",
       "240   0.000000e+00     59.875774     59.754925      1126.6584       0.001502   \n",
       "\n",
       "     ...  CWL_SEC_PM_POW_2  CWL_SEC_PM_SPD_1  CWL_SEC_PM_SPD_2  \\\n",
       "0    ...          0.000000          1.000000          0.000000   \n",
       "60   ...         51.716137          1.000000          1.000000   \n",
       "120  ...         51.716137          1.000000          1.000000   \n",
       "180  ...         48.771226          0.982353          0.982353   \n",
       "240  ...         11.441535          0.619520          0.619520   \n",
       "\n",
       "     CWL_SEC_PM_STA_1  CWL_SEC_PM_STA_2  CWL_SEC_RW_TEMP  CWL_SEC_SW_TEMP  \\\n",
       "0                 1.0               0.0        56.816963        57.150177   \n",
       "60                1.0               1.0        56.060660        56.109330   \n",
       "120               1.0               1.0        54.338280        54.349762   \n",
       "180               1.0               1.0        53.982270        53.984024   \n",
       "240               1.0               1.0        53.952988        53.952496   \n",
       "\n",
       "       OA_TEMP  OA_TEMP_WB  TWV_CTRL  \n",
       "0     9.070051   10.355011  0.000000  \n",
       "60    9.612884   10.925037  0.000902  \n",
       "120  10.632746   12.002028  0.031300  \n",
       "180  10.649775   12.019989  0.394997  \n",
       "240  11.487482   12.904993  0.610889  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine All Fault and Fault-free Case and Labeling\n",
    "\n",
    "def process_df(file_name, fault_value, interval=60):\n",
    "    df = pd.read_csv(file_name)\n",
    "    df = df.iloc[::interval, :]  # Take data from every 'interval' rows\n",
    "    df.insert(1, 'Fault', fault_value)\n",
    "    return df\n",
    "\n",
    "# Normal\n",
    "df_unfaulted = process_df('ChillerPlant.csv', \"N\", interval=60)\n",
    "\n",
    "# WCC Sensors Bias - 2 ways\n",
    "# Chilled water leaving temperature sensor bias of chiller 1 \n",
    "df_CH_bias1_faulted = process_df('ChillerPlant_chiller_bias_2.csv', \"CHS\", interval=240)\n",
    "df_CH_bias2_faulted = process_df('ChillerPlant_chiller_bias_-2.csv', \"CHS\", interval=240)\n",
    "df_CH_bias3_faulted = process_df('ChillerPlant_chiller_bias_1.csv', \"CHS\", interval=240)\n",
    "df_CH_bias4_faulted = process_df('ChillerPlant_chiller_bias_-1.csv', \"CHS\", interval=240)\n",
    "\n",
    "# CT Sensors Bias - 2 ways\n",
    "# Condenser water leaving temperature sensor bias of cooling tower 1 \n",
    "df_CT_bias1_faulted = process_df('ChillerPlant_coolingtower_bias_2.csv', \"CTS\", interval=240)\n",
    "df_CT_bias2_faulted = process_df('ChillerPlant_coolingtower_bias_-2.csv', \"CTS\", interval=240)\n",
    "df_CT_bias3_faulted = process_df('ChillerPlant_coolingtower_bias_1.csv', \"CTS\", interval=240)\n",
    "df_CT_bias4_faulted = process_df('ChillerPlant_coolingtower_bias_-1.csv', \"CTS\", interval=240)\n",
    "\n",
    "# CT Water Scale - 2 ways\n",
    "# Fouling of cooling tower heat exchanger\n",
    "df_CT_foul1_faulted = process_df('ChillerPlant_coolingtower_fouling_065.csv', \"CTF\", interval=180)\n",
    "df_CT_foul2_faulted = process_df('ChillerPlant_coolingtower_fouling_080.csv', \"CTF\", interval=180)\n",
    "df_CT_foul3_faulted = process_df('ChillerPlant_coolingtower_fouling_095.csv', \"CTF\", interval=180)\n",
    "\n",
    "# Pump Pressure Bias - 2 ways\n",
    "# Differential pressure sensor bias in the secondary chilled water loop\n",
    "df_CHWP_pressure1_faulted = process_df('ChillerPlant_secondary_chilled_water_pressure_bias_020.csv', \"CPP\", interval=240)\n",
    "df_CHWP_pressure2_faulted = process_df('ChillerPlant_secondary_chilled_water_pressure_bias_-020.csv', \"CPP\", interval=240)\n",
    "df_CHWP_pressure3_faulted = process_df('ChillerPlant_secondary_chilled_water_pressure_bias_010.csv', \"CPP\", interval=240)\n",
    "df_CHWP_pressure4_faulted = process_df('ChillerPlant_secondary_chilled_water_pressure_bias_-010.csv', \"CPP\", interval=240)\n",
    "\n",
    "# Valve Bypass Leakage - 1 way\n",
    "# Leakage of the condenser water leaving the three-way valve\n",
    "df_Bypass_leakage1_faulted = process_df('ChillerPlant_bypass_leakage_025.csv', \"BPL\", interval=180)\n",
    "df_Bypass_leakage2_faulted = process_df('ChillerPlant_bypass_leakage_050.csv', \"BPL\", interval=180)\n",
    "df_Bypass_leakage3_faulted = process_df('ChillerPlant_bypass_leakage_075.csv', \"BPL\", interval=180)\n",
    "\n",
    "# Valve Bypass Stuck - 1 way\n",
    "# Stuck of the condenser water leaving the three-way valve\n",
    "df_Bypass_stuck1_faulted = process_df('ChillerPlant_bypass_stuck_050.csv', \"BPS\", interval=120)\n",
    "df_Bypass_stuck2_faulted = process_df('ChillerPlant_bypass_stuck_075.csv', \"BPS\", interval=120)\n",
    "\n",
    "# CT Control Faulut - 1 way\n",
    "# PID control for condenser water supply temperature\n",
    "df_CT_PID_faulted = process_df('ChillerPlant_coolingtower_PI.csv', \"CTPID\", interval=60)\n",
    "\n",
    "# Concat All Cases\n",
    "DFs = pd.concat([\n",
    "    df_unfaulted,\n",
    "    df_CH_bias1_faulted, df_CH_bias2_faulted, df_CH_bias3_faulted, df_CH_bias4_faulted,\n",
    "    df_CT_bias1_faulted, df_CT_bias2_faulted, df_CT_bias3_faulted, df_CT_bias4_faulted,\n",
    "    df_CT_foul1_faulted, df_CT_foul2_faulted, df_CT_foul3_faulted,\n",
    "    df_CHWP_pressure1_faulted, df_CHWP_pressure2_faulted, df_CHWP_pressure3_faulted, df_CHWP_pressure4_faulted,\n",
    "    df_Bypass_leakage1_faulted, df_Bypass_leakage2_faulted, df_Bypass_leakage3_faulted,\n",
    "    df_Bypass_stuck1_faulted, df_Bypass_stuck2_faulted,\n",
    "    df_CT_PID_faulted\n",
    "])\n",
    "\n",
    "DFs.head()\n",
    "\n",
    "#DF.tail()\n",
    "#print(len(DF))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fault\n",
      "CHS      8760\n",
      "CTS      8760\n",
      "CTF      8760\n",
      "CPP      8760\n",
      "BPL      8760\n",
      "BPS      8760\n",
      "N        8759\n",
      "CTPID    8759\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "DF_main = DFs # Make a COPY\n",
    "#print(DF_main)\n",
    "\n",
    "# Faults Statistics\n",
    "fault_counts = DF_main['Fault'].value_counts()\n",
    "print(fault_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Units Convert\n",
    "\n",
    "# Convert all \"TEMP\" from F to C\n",
    "def fahrenheit_to_celsius(f):\n",
    "    return (f - 32) * 5.0/9.0\n",
    "\n",
    "temp_columns = DF_main.filter(regex='TEMP')\n",
    "DF_main[temp_columns.columns] = DF_main[temp_columns.columns].map(fahrenheit_to_celsius)\n",
    "\n",
    "# Convert all \"FLOW\" from GPM to L/s\n",
    "def gpm_to_ls(gpm):\n",
    "    return gpm * 0.0631\n",
    "\n",
    "flow_columns = DF_main.filter(regex='FLOW')\n",
    "DF_main[flow_columns.columns] = DF_main[flow_columns.columns].map(gpm_to_ls)\n",
    "\n",
    "# Convert CWL_SEC_LOAD from W to kW\n",
    "DF_main['CWL_SEC_LOAD'] = DF_main['CWL_SEC_LOAD'] / 1000\n",
    "\n",
    "# Swap Dry Bulb and Wet Bulb Temperatures => Original Data Incorrect!\n",
    "DF_main.rename(columns={'OA_TEMP': 'TEMP_TEMP', 'OA_TEMP_WB': 'OA_TEMP'}, inplace=True)\n",
    "DF_main.rename(columns={'TEMP_TEMP': 'OA_TEMP_WB'}, inplace=True)\n",
    "\n",
    "#print(DF_main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modification: Constant and Noise Data (Decimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CHL_COMP_SPD_CTRL_1', 'CHL_COMP_SPD_CTRL_2', 'CHL_COMP_SPD_CTRL_3', 'CT_FAN_SPD_1', 'CT_FAN_SPD_2', 'CT_FAN_SPD_3', 'CT_FAN_SPD_CTRL_1', 'CT_FAN_SPD_CTRL_2', 'CT_FAN_SPD_CTRL_3', 'CWL_SEC_PM_SPD_1', 'CWL_SEC_PM_SPD_2', 'CT_SW_TEMPSPT', 'CWL_PRI_SW_TEMPSPT', 'CWL_SEC_DPSPT']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nDF_main[decimal3] = DF_main[decimal3].astype(float).round(3)\\n#print(DF_main[decimal3])\\n\\n# Round up to 3 decimal\\ncategorical_columns = ['Datetime', 'Fault']\\ndecimal2 = DF_main.columns.difference(decimal3 + categorical_columns) # Not in decimal3 or categorical_columns\\nDF_main[decimal2] = DF_main[decimal2].astype(float).round(2)\\n#print(DF_main[decimal2])\\n\\n\\n# Filter the Noise Data (Power Meter)\\nnoise = ['CDWL_PM_POW_1', 'CDWL_PM_POW_2', 'CDWL_PM_POW_3', 'CWL_PRI_PM_POW_1', 'CWL_PRI_PM_POW_2', 'CWL_PRI_PM_POW_3', 'CWL_SEC_PM_POW_1', 'CWL_SEC_PM_POW_2', 'CT_FLOW_1', 'CT_FLOW_2', 'CT_FLOW_3']\\nDF_main[noise] = DF_main[noise].mask(DF_main[noise] < 1, 0)\\n\\nDF_main.head()\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Round up to 2 decimal\n",
    "SPD_columns = DF_main.filter(regex=r'SPD') # Key: \"SPD\"\n",
    "SPT_columns = DF_main.filter(regex=r'SPT')\n",
    "decimal3 = list(SPD_columns.columns) + list(SPT_columns.columns)\n",
    "DF_main[decimal3] = DF_main[decimal3].astype(float).round(3)\n",
    "#print(DF_main[decimal3])\n",
    "\n",
    "# Round up to 3 decimal\n",
    "categorical_columns = ['Datetime', 'Fault']\n",
    "decimal2 = DF_main.columns.difference(decimal3 + categorical_columns) # Not in decimal3 or categorical_columns\n",
    "DF_main[decimal2] = DF_main[decimal2].astype(float).round(2)\n",
    "#print(DF_main[decimal2])\n",
    "\n",
    "\n",
    "# Filter the Noise Data (Power Meter)\n",
    "noise = ['CDWL_PM_POW_1', 'CDWL_PM_POW_2', 'CDWL_PM_POW_3', 'CWL_PRI_PM_POW_1', 'CWL_PRI_PM_POW_2', 'CWL_PRI_PM_POW_3', 'CWL_SEC_PM_POW_1', 'CWL_SEC_PM_POW_2', 'CT_FLOW_1', 'CT_FLOW_2', 'CT_FLOW_3']\n",
    "DF_main[noise] = DF_main[noise].mask(DF_main[noise] < 1, 0)\n",
    "\n",
    "DF_main.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Cleaning: Base Data (Turned-off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into sub-data set\n",
    "CHL_columns = [col for col in DF_main.columns if \"CHL_\" in col]\n",
    "df_CHL = DF_main[CHL_columns]\n",
    "\n",
    "CT_columns = [col for col in DF_main.columns if \"CT_\" in col]\n",
    "df_CT = DF_main[CT_columns]\n",
    "\n",
    "CDWL_columns = [col for col in DF_main.columns if \"CDWL_\" in col]\n",
    "df_CDWL = DF_main[CDWL_columns]\n",
    "\n",
    "CWL_PRI_columns = [col for col in DF_main.columns if \"CWL_PRI_\" in col]\n",
    "df_CWL_PRI = DF_main[CWL_PRI_columns]\n",
    "\n",
    "CWL_SEC_columns = [col for col in DF_main.columns if \"CWL_SEC_\" in col]\n",
    "df_CWL_SEC = DF_main[CWL_SEC_columns]\n",
    "\n",
    "Other_columns = CHL_columns + CT_columns + CDWL_columns + CWL_PRI_columns + CWL_SEC_columns\n",
    "df_Other = DF_main.drop(columns=Other_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        CHL_STA_1\n",
      "0             1.0\n",
      "60            1.0\n",
      "120           1.0\n",
      "180           1.0\n",
      "240           1.0\n",
      "...           ...\n",
      "525240        1.0\n",
      "525300        1.0\n",
      "525360        1.0\n",
      "525420        1.0\n",
      "525480        1.0\n",
      "\n",
      "[70078 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Remove noise data: Power Meter and Flow Meter and TEMP Sensor\n",
    "def clean_CHL_data(df, suffix):\n",
    "    # If STATUS == 0; TEMP == 0, FLOW == 0, POW == 0\n",
    "    CHL_X = df.filter(regex=fr'^CHL_.*{suffix}$')\n",
    "    sta_columns = CHL_X.filter(regex=r'^CHL_STA') # Key\n",
    "    pow_columns = CHL_X.filter(regex=r'^CHL_POW')\n",
    "    flow_columns = CHL_X.filter(regex=r'^CHL_.*_FLOW_.*')\n",
    "    temp_columns = CHL_X.filter(regex=r'^CHL_.*_TEMP_.*')\n",
    "    columns_to_modify = list(pow_columns.columns) + list(flow_columns.columns) + list(temp_columns.columns)\n",
    "    #print(columns_to_modify)\n",
    "    CHL_X.loc[CHL_X[sta_columns.columns].eq(0).any(axis=1), columns_to_modify] = 0\n",
    "    return CHL_X\n",
    "\n",
    "def clean_CT_data(df, suffix):\n",
    "    # If STATUS == 0; TEMP == 0, FLOW == 0, POW == 0\n",
    "    CT_X = df.filter(regex=fr'^CT_.*{suffix}$')\n",
    "    sta_columns = CT_X.filter(regex=r'^CT_STA') # Key\n",
    "    pow_columns = CT_X.filter(regex=r'^CT_POW')\n",
    "    temp_columns = CT_X.filter(regex=r'^CT_.*_TEMP_.*')\n",
    "    flow_columns = CT_X.filter(regex=r'^CT_.*_FLOW_.*')\n",
    "    columns_to_modify = list(pow_columns.columns) + list(temp_columns.columns) + list(flow_columns.columns)\n",
    "    #print(columns_to_modify)\n",
    "    CT_X.loc[CT_X[sta_columns.columns].eq(0).any(axis=1), columns_to_modify] = 0\n",
    "    return CT_X\n",
    "\n",
    "# Update back to df_CHL\n",
    "df_CHL.update(clean_CHL_data(df_CHL, '_1'))\n",
    "df_CHL.update(clean_CHL_data(df_CHL, '_2'))\n",
    "df_CHL.update(clean_CHL_data(df_CHL, '_3'))\n",
    "\n",
    "# Update back to df_CT\n",
    "df_CT.update(clean_CT_data(df_CT, '_1'))\n",
    "df_CT.update(clean_CT_data(df_CT, '_2'))\n",
    "df_CT.update(clean_CT_data(df_CT, '_3'))\n",
    "\n",
    "# Update df_CHL and df_CT back to DF_main\n",
    "DF_main.update(df_CHL)\n",
    "DF_main.update(df_CT)\n",
    "\n",
    "DF_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For output only\n",
    "\n",
    "constants = ['CHL_CD_FLOW_1', 'CHL_CD_FLOW_2', 'CHL_CD_FLOW_3', 'CHL_CW_FLOW_1', 'CHL_CW_FLOW_2', 'CHL_CW_FLOW_3', 'CWL_SEC_DPSPT']\n",
    "DF_main_clean = DF_main.drop(columns=constants) # After adding after adding the new features, before output.\n",
    "\n",
    "DF_main_clean.head()\n",
    "\n",
    "# One Sheet\n",
    "with pd.ExcelWriter('df_faults_woF.xlsx', engine='xlsxwriter') as writer:\n",
    "    DF_main_clean.to_excel(writer, sheet_name='main')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output By_Components\n",
    "CHL_columns = [col for col in DF_main_clean.columns if \"CHL_\" in col]\n",
    "df_CHL = DF_main_clean[CHL_columns]\n",
    "\n",
    "CT_columns = [col for col in DF_main_clean.columns if \"CT_\" in col]\n",
    "df_CT = DF_main_clean[CT_columns]\n",
    "\n",
    "CDWL_columns = [col for col in DF_main_clean.columns if \"CDWL_\" in col]\n",
    "df_CDWL = DF_main_clean[CDWL_columns]\n",
    "\n",
    "CWL_PRI_columns = [col for col in DF_main_clean.columns if \"CWL_PRI_\" in col]\n",
    "df_CWL_PRI = DF_main_clean[CWL_PRI_columns]\n",
    "\n",
    "CWL_SEC_columns = [col for col in DF_main_clean.columns if \"CWL_SEC_\" in col]\n",
    "df_CWL_SEC = DF_main_clean[CWL_SEC_columns]\n",
    "\n",
    "Other_columns = CHL_columns + CT_columns + CDWL_columns + CWL_PRI_columns + CWL_SEC_columns\n",
    "df_Other = DF_main_clean.drop(columns=Other_columns)\n",
    "\n",
    "# For Temporary Review\n",
    "with pd.ExcelWriter('Components_woF.xlsx', engine='xlsxwriter') as writer:\n",
    "    df_CHL.to_excel(writer, sheet_name='CHL_Data')\n",
    "    df_CT.to_excel(writer, sheet_name='CT_Data')\n",
    "    df_CDWL.to_excel(writer, sheet_name='CDWL_Data')\n",
    "    df_CWL_PRI.to_excel(writer, sheet_name='CWL_PRI_Data')\n",
    "    df_CWL_SEC.to_excel(writer, sheet_name='CWL_SEC_Data')\n",
    "    df_Other.to_excel(writer, sheet_name='Other_Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ww/p9m_hngn1_ldx7wx31htxv_r0000gn/T/ipykernel_8246/3566979502.py:87: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['CT_Load_2'] = df.apply(\n",
      "/var/folders/ww/p9m_hngn1_ldx7wx31htxv_r0000gn/T/ipykernel_8246/3566979502.py:91: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['CT_Eff_2'] = df.apply(\n",
      "/var/folders/ww/p9m_hngn1_ldx7wx31htxv_r0000gn/T/ipykernel_8246/3566979502.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['CT_ApproachTEMP_2'] = df.apply(\n",
      "/var/folders/ww/p9m_hngn1_ldx7wx31htxv_r0000gn/T/ipykernel_8246/3566979502.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['CT_Error_2'] = df.apply(\n",
      "/var/folders/ww/p9m_hngn1_ldx7wx31htxv_r0000gn/T/ipykernel_8246/3566979502.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['CT_Dist_2'] = df.apply(\n",
      "/var/folders/ww/p9m_hngn1_ldx7wx31htxv_r0000gn/T/ipykernel_8246/3566979502.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['CT_DeltaTEMP_3'] = df.apply(\n",
      "/var/folders/ww/p9m_hngn1_ldx7wx31htxv_r0000gn/T/ipykernel_8246/3566979502.py:113: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['CT_Load_3'] = df.apply(\n",
      "/var/folders/ww/p9m_hngn1_ldx7wx31htxv_r0000gn/T/ipykernel_8246/3566979502.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['CT_Eff_3'] = df.apply(\n",
      "/var/folders/ww/p9m_hngn1_ldx7wx31htxv_r0000gn/T/ipykernel_8246/3566979502.py:121: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['CT_ApproachTEMP_3'] = df.apply(\n",
      "/var/folders/ww/p9m_hngn1_ldx7wx31htxv_r0000gn/T/ipykernel_8246/3566979502.py:125: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['CT_Error_3'] = df.apply(\n",
      "/var/folders/ww/p9m_hngn1_ldx7wx31htxv_r0000gn/T/ipykernel_8246/3566979502.py:129: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['CT_Dist_3'] = df.apply(\n",
      "/var/folders/ww/p9m_hngn1_ldx7wx31htxv_r0000gn/T/ipykernel_8246/3566979502.py:134: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['CT_TotalFLOW'] = df['CT_FLOW_1'] + df['CT_FLOW_2'] + df['CT_FLOW_3']\n",
      "/var/folders/ww/p9m_hngn1_ldx7wx31htxv_r0000gn/T/ipykernel_8246/3566979502.py:139: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['CDWL_POW'] = df.apply(\n",
      "/var/folders/ww/p9m_hngn1_ldx7wx31htxv_r0000gn/T/ipykernel_8246/3566979502.py:142: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['CDWL_DeltaTEMP'] = df.apply(\n",
      "/var/folders/ww/p9m_hngn1_ldx7wx31htxv_r0000gn/T/ipykernel_8246/3566979502.py:146: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['CDWL_Load'] = df.apply(\n",
      "/var/folders/ww/p9m_hngn1_ldx7wx31htxv_r0000gn/T/ipykernel_8246/3566979502.py:150: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['CDWL_Error'] = df['CT_SW_TEMPSPT'] - df['CDWL_SW_TEMP']\n",
      "/var/folders/ww/p9m_hngn1_ldx7wx31htxv_r0000gn/T/ipykernel_8246/3566979502.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['CDWL_DeltaFLOW'] = df['CHL_CD_TotalFLOW'] - df['CT_TotalFLOW'] # Bypass How Many FLow\n",
      "/var/folders/ww/p9m_hngn1_ldx7wx31htxv_r0000gn/T/ipykernel_8246/3566979502.py:157: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['CWL_PRI_POW'] = df.apply(\n",
      "/var/folders/ww/p9m_hngn1_ldx7wx31htxv_r0000gn/T/ipykernel_8246/3566979502.py:160: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['CWL_PRI_DeltaTEMP'] = df.apply(\\\n",
      "/var/folders/ww/p9m_hngn1_ldx7wx31htxv_r0000gn/T/ipykernel_8246/3566979502.py:164: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['CWL_PRI_Load'] = df.apply(\n",
      "/var/folders/ww/p9m_hngn1_ldx7wx31htxv_r0000gn/T/ipykernel_8246/3566979502.py:168: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['CWL_SEC_POW'] = df.apply(\n",
      "/var/folders/ww/p9m_hngn1_ldx7wx31htxv_r0000gn/T/ipykernel_8246/3566979502.py:178: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Relative_Humidity'] = df.apply(lambda row: RH(row['OA_TEMP'], row['OA_TEMP_WB']), axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Adding Features\n",
    "\n",
    "# WCC\n",
    "def add_WCC(df):\n",
    "    # WCC1\n",
    "    df['CHL_DeltaTEMP_1'] = df.apply(\n",
    "        lambda row: (row['CHL_RW_TEMP_1'] - row['CHL_SW_TEMP_1'])\n",
    "                     if row['CHL_POW_1'] > 5 else 0,\n",
    "        axis=1)\n",
    "    df['CHL_Cooling_Load_1'] = df.apply(\n",
    "        lambda row: (row['CHL_DeltaTEMP_1']) * (row['CHL_CW_FLOW_1']) * 4.18 \n",
    "                     if row['CHL_POW_1'] > 5 else 0,\n",
    "        axis=1)\n",
    "    df['CHL_COP_1'] = df.apply(\n",
    "        lambda row: (row['CHL_Cooling_Load_1'] / row['CHL_POW_1'])\n",
    "                    if row['CHL_POW_1'] > 5 else 0,\n",
    "        axis=1)\n",
    "    df['PLANT_POW_1'] = df['CHL_POW_1'] + df['CT_POW_1'] + df['CDWL_PM_POW_1'] + df['CWL_PRI_PM_POW_1']\n",
    "\n",
    "    # WCC2\n",
    "    df['CHL_DeltaTEMP_2'] = df.apply(\n",
    "        lambda row: (row['CHL_RW_TEMP_2'] - row['CHL_SW_TEMP_2'])\n",
    "                     if row['CHL_POW_2'] > 5 else 0,\n",
    "        axis=1)\n",
    "    df['CHL_Cooling_Load_2'] = df.apply(\n",
    "        lambda row: (row['CHL_DeltaTEMP_2']) * (row['CHL_CW_FLOW_2']) * 4.18 \n",
    "                     if row['CHL_POW_2'] > 5 else 0,\n",
    "        axis=1)\n",
    "    df['CHL_COP_2'] = df.apply(\n",
    "        lambda row: (row['CHL_Cooling_Load_2'] / row['CHL_POW_2'])\n",
    "                    if row['CHL_POW_2'] > 5 else 0,\n",
    "        axis=1)\n",
    "    df['PLANT_POW_2'] = df['CHL_POW_2'] + df['CT_POW_2'] + df['CDWL_PM_POW_2'] + df['CWL_PRI_PM_POW_2']\n",
    "\n",
    "    #WCC3\n",
    "    df['CHL_DeltaTEMP_3'] = df.apply(\n",
    "        lambda row: (row['CHL_RW_TEMP_3'] - row['CHL_SW_TEMP_3'])\n",
    "                     if row['CHL_POW_3'] > 5 else 0,\n",
    "        axis=1)\n",
    "    df['CHL_Cooling_Load_3'] = df.apply(\n",
    "        lambda row: (row['CHL_DeltaTEMP_3']) * (row['CHL_CW_FLOW_3']) * 4.18 \n",
    "                     if row['CHL_POW_3'] > 5 else 0,\n",
    "        axis=1)\n",
    "    df['CHL_COP_3'] = df.apply(\n",
    "        lambda row: (row['CHL_Cooling_Load_3'] / row['CHL_POW_3'])\n",
    "                    if row['CHL_POW_3'] > 5 else 0,\n",
    "        axis=1)\n",
    "    df['PLANT_POW_3'] = df['CHL_POW_3'] + df['CT_POW_3'] + df['CDWL_PM_POW_3'] + df['CWL_PRI_PM_POW_3']\n",
    "\n",
    "    df['CHL_CW_TotalFLOW'] = df['CHL_CW_FLOW_1'] + df['CHL_CW_FLOW_2'] + df['CHL_CW_FLOW_3']\n",
    "    df['CHL_CD_TotalFLOW'] = df['CHL_CD_FLOW_1'] + df['CHL_CD_FLOW_2'] + df['CHL_CD_FLOW_3']\n",
    "    return df\n",
    "\n",
    "# Cooling Tower\n",
    "def add_CT(df):\n",
    "    # CT1\n",
    "    df['CT_DeltaTEMP_1'] = df.apply(\n",
    "        lambda row: (row['CT_RW_TEMP_1'] - row['CT_SW_TEMP_1'])\n",
    "                     if row['CT_FAN_SPD_1'] != 0 else 0,\n",
    "        axis=1)\n",
    "    df['CT_Load_1'] = df.apply(\n",
    "        lambda row: row['CT_DeltaTEMP_1'] * row['CT_FLOW_1'] * 4.18 \n",
    "                     if row['CT_FAN_SPD_1'] != 0 else 0,\n",
    "        axis=1)\n",
    "    df['CT_Eff_1'] = df.apply(\n",
    "        lambda row: (row['CT_Load_1'] / row['CT_POW_1']) \n",
    "                        if row['CT_FAN_SPD_1'] != 0 and row['CT_POW_1'] != 0 else 0,\n",
    "        axis=1)\n",
    "    df['CT_ApproachTEMP_1'] = df.apply(\n",
    "        lambda row: (row['OA_TEMP_WB'] - row['CT_SW_TEMP_1'])\n",
    "                     if row['CT_FAN_SPD_1'] != 0 else 0,\n",
    "        axis=1)\n",
    "    df['CT_Error_1'] = df.apply(\n",
    "        lambda row: (row['CT_SW_TEMPSPT'] - row['CT_SW_TEMP_1'])\n",
    "                     if row['CT_FAN_SPD_1'] != 0 else 0,\n",
    "        axis=1)\n",
    "    df['CT_Dist_1'] = df.apply(\n",
    "        lambda row: row['CT_POW_1'] / row['PLANT_POW_1']\n",
    "                     if row['CT_POW_1'] != 0 else 0,\n",
    "        axis=1)\n",
    "    \n",
    "    # CT2\n",
    "    df['CT_DeltaTEMP_2'] = df.apply(\n",
    "        lambda row: (row['CT_RW_TEMP_2'] - row['CT_SW_TEMP_2'])\n",
    "                        if row['CT_FAN_SPD_2'] != 0 else 0,\n",
    "        axis=1)\n",
    "    df['CT_Load_2'] = df.apply(\n",
    "        lambda row: row['CT_DeltaTEMP_2'] * row['CT_FLOW_2'] * 4.18 \n",
    "                     if row['CT_FAN_SPD_2'] != 0 else 0,\n",
    "        axis=1)\n",
    "    df['CT_Eff_2'] = df.apply(\n",
    "        lambda row: (row['CT_Load_2'] / row['CT_POW_2']) \n",
    "                        if row['CT_FAN_SPD_2'] != 0 and row['CT_POW_2'] != 0 else 0,\n",
    "        axis=1)\n",
    "    df['CT_ApproachTEMP_2'] = df.apply(\n",
    "        lambda row: (row['OA_TEMP_WB'] - row['CT_SW_TEMP_2'])\n",
    "                     if row['CT_FAN_SPD_2'] != 0 else 0,\n",
    "        axis=1)\n",
    "    df['CT_Error_2'] = df.apply(\n",
    "        lambda row: (row['CT_SW_TEMPSPT'] - row['CT_SW_TEMP_2'])\n",
    "                     if row['CT_FAN_SPD_2'] != 0 else 0,\n",
    "        axis=1)\n",
    "    df['CT_Dist_2'] = df.apply(\n",
    "        lambda row: row['CT_POW_2'] / row['PLANT_POW_2']\n",
    "                     if row['CT_POW_2'] != 0 else 0,\n",
    "        axis=1)\n",
    "        \n",
    "    # CT3\n",
    "    df['CT_DeltaTEMP_3'] = df.apply(\n",
    "        lambda row: (row['CT_RW_TEMP_3'] - row['CT_SW_TEMP_3'])\n",
    "                        if row['CT_FAN_SPD_3'] != 0 else 0,\n",
    "        axis=1)\n",
    "    df['CT_Load_3'] = df.apply(\n",
    "        lambda row: row['CT_DeltaTEMP_3'] * row['CT_FLOW_3'] * 4.18 \n",
    "                     if row['CT_FAN_SPD_3'] != 0 else 0,\n",
    "        axis=1)\n",
    "    df['CT_Eff_3'] = df.apply(\n",
    "        lambda row: (row['CT_Load_3'] / row['CT_POW_3']) \n",
    "                        if row['CT_FAN_SPD_3'] != 0 and row['CT_POW_3'] != 0 else 0,\n",
    "        axis=1)\n",
    "    df['CT_ApproachTEMP_3'] = df.apply(\n",
    "        lambda row: (row['OA_TEMP_WB'] - row['CT_SW_TEMP_3'])\n",
    "                     if row['CT_FAN_SPD_3'] != 0 else 0,\n",
    "        axis=1)\n",
    "    df['CT_Error_3'] = df.apply(\n",
    "        lambda row: (row['CT_SW_TEMPSPT'] - row['CT_SW_TEMP_3'])\n",
    "                     if row['CT_FAN_SPD_3'] != 0 else 0,\n",
    "        axis=1)\n",
    "    df['CT_Dist_3'] = df.apply(\n",
    "        lambda row: row['CT_POW_3'] / row['PLANT_POW_3']\n",
    "                     if row['CT_POW_3'] != 0 else 0,\n",
    "        axis=1)\n",
    "    \n",
    "    df['CT_TotalFLOW'] = df['CT_FLOW_1'] + df['CT_FLOW_2'] + df['CT_FLOW_3']\n",
    "    return df\n",
    "\n",
    "# Condensation Side\n",
    "def add_CDWL(df):    \n",
    "    df['CDWL_POW'] = df.apply(\n",
    "        lambda row: row['CDWL_PM_POW_1'] + row['CDWL_PM_POW_2'] + row['CDWL_PM_POW_3'],\n",
    "        axis=1)\n",
    "    df['CDWL_DeltaTEMP'] = df.apply(\n",
    "        lambda row: (row['CDWL_RW_TEMP'] - row['CDWL_SW_TEMP'])\n",
    "                     if row['CDWL_POW'] != 0 else 0,\n",
    "        axis=1)\n",
    "    df['CDWL_Load'] = df.apply(\n",
    "        lambda row: row['CDWL_DeltaTEMP'] * row['CDWL_CW_FLOW'] * 4.18\n",
    "                     if row['CDWL_POW'] != 0 else 0,\n",
    "        axis=1)\n",
    "    df['CDWL_Error'] = df['CT_SW_TEMPSPT'] - df['CDWL_SW_TEMP']\n",
    "    \n",
    "    df['CDWL_DeltaFLOW'] = df['CHL_CD_TotalFLOW'] - df['CT_TotalFLOW'] # Bypass How Many FLow\n",
    "    return df\n",
    "\n",
    "# Chilled Side\n",
    "def add_CWL_PRI(df):\n",
    "    df['CWL_PRI_POW'] = df.apply(\n",
    "        lambda row: row['CWL_PRI_PM_POW_1'] + row['CWL_PRI_PM_POW_2'] + row['CWL_PRI_PM_POW_3'],\n",
    "        axis=1)\n",
    "    df['CWL_PRI_DeltaTEMP'] = df.apply(\\\n",
    "        lambda row: (row['CWL_PRI_RW_TEMP'] - row['CWL_PRI_SW_TEMP'])\n",
    "                     if row['CWL_PRI_POW'] != 0 else 0,\n",
    "        axis=1)\n",
    "    df['CWL_PRI_Load'] = df.apply(\n",
    "        lambda row: row['CWL_PRI_DeltaTEMP'] * row['CWL_PRI_CW_FLOW'] * 4.18\n",
    "                     if row['CWL_PRI_POW'] != 0 else 0,\n",
    "        axis=1)\n",
    "    df['CWL_SEC_POW'] = df.apply(\n",
    "        lambda row: row['CWL_SEC_PM_POW_1'] + row['CWL_SEC_PM_POW_2'],\n",
    "        axis=1)\n",
    "    return df\n",
    "\n",
    "# Other\n",
    "def add_RH(df):\n",
    "    psychrolib.SetUnitSystem(psychrolib.SI)\n",
    "    def RH(outdoor_temp, wet_bulb_temp):\n",
    "        return psychrolib.GetRelHumFromTWetBulb(outdoor_temp, wet_bulb_temp, 101325)\n",
    "    df['Relative_Humidity'] = df.apply(lambda row: RH(row['OA_TEMP'], row['OA_TEMP_WB']), axis=1)\n",
    "    df['Relative_Humidity'] = df['Relative_Humidity'].round(3)\n",
    "    return df\n",
    "\n",
    "# Apply New Features by orginial DF_main\n",
    "DF_main = add_WCC(DF_main)\n",
    "DF_main = add_CT(DF_main)\n",
    "DF_main = add_CDWL(DF_main)\n",
    "DF_main = add_CWL_PRI(DF_main)\n",
    "DF_main = add_RH(DF_main)\n",
    "\n",
    "constants = ['CHL_CD_FLOW_1', 'CHL_CD_FLOW_2', 'CHL_CD_FLOW_3', 'CHL_CW_FLOW_1', 'CHL_CW_FLOW_2', 'CHL_CW_FLOW_3', 'CWL_SEC_DPSPT']\n",
    "DF_main = DF_main.drop(columns=constants) # After adding after adding the new features, before output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output data files (with new features)\n",
    "with pd.ExcelWriter('df_faults_even.xlsx', engine='xlsxwriter') as writer:\n",
    "    DF_main.to_excel(writer, sheet_name='main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into sub-data set\n",
    "\n",
    "CHL_columns = [col for col in DF_main.columns if \"CHL_\" in col]\n",
    "df_CHL = DF_main[CHL_columns]\n",
    "\n",
    "CT_columns = [col for col in DF_main.columns if \"CT_\" in col]\n",
    "df_CT = DF_main[CT_columns]\n",
    "\n",
    "CDWL_columns = [col for col in DF_main.columns if \"CDWL_\" in col]\n",
    "df_CDWL = DF_main[CDWL_columns]\n",
    "\n",
    "CWL_PRI_columns = [col for col in DF_main.columns if \"CWL_PRI_\" in col]\n",
    "df_CWL_PRI = DF_main[CWL_PRI_columns]\n",
    "\n",
    "CWL_SEC_columns = [col for col in DF_main.columns if \"CWL_SEC_\" in col]\n",
    "df_CWL_SEC = DF_main[CWL_SEC_columns]\n",
    "\n",
    "Other_columns = CHL_columns + CT_columns + CDWL_columns + CWL_PRI_columns + CWL_SEC_columns\n",
    "df_Other = DF_main.drop(columns=Other_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output By_Components\n",
    "\n",
    "with pd.ExcelWriter('Components_faults_even.xlsx', engine='xlsxwriter') as writer:\n",
    "    df_CHL.to_excel(writer, sheet_name='CHL_Data')\n",
    "    df_CT.to_excel(writer, sheet_name='CT_Data')\n",
    "    df_CDWL.to_excel(writer, sheet_name='CDWL_Data')\n",
    "    df_CWL_PRI.to_excel(writer, sheet_name='CWL_PRI_Data')\n",
    "    df_CWL_SEC.to_excel(writer, sheet_name='CWL_SEC_Data')\n",
    "    df_Other.to_excel(writer, sheet_name='Other_Data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'df_faults_clean.xlsx' => cleaned the noise without new features\n",
    "\n",
    "### 'df_faults.xlsx' with new features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
