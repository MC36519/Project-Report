{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from scipy.stats import loguniform\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.feature_selection import RFE, VarianceThreshold\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV, RandomizedSearchCV, cross_val_predict\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier, BaggingClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, LabelBinarizer\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Data Set\n",
    "path = '/Users/lks/Desktop/UM/Project Report/01_LBNL_FDD_Even/df_faults_even.xlsx'\n",
    "path2 = '/Users/lks/Desktop/UM/Project Report/01_LBNL_FDD_Even/df_faults_woF.xlsx'\n",
    "\n",
    "DF_faulty = pd.read_excel(path, index_col=0) # Engineered Feature Set\n",
    "DF_faulty2 = pd.read_excel(path2, index_col=0) # Original Feature Set\n",
    "\n",
    "\n",
    "df_filtered = DF_faulty2 # Switch to DF_faulty2 if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "X = df_filtered.drop(columns=['Datetime', 'Fault'])\n",
    "y = df_filtered['Fault']\n",
    "\n",
    "# Encode the target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Classifiers with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lks/anaconda3/envs/Project/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/lks/anaconda3/envs/Project/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/lks/anaconda3/envs/Project/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/lks/anaconda3/envs/Project/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/lks/anaconda3/envs/Project/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Classification Report (CV on Training Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BPL       0.58      0.30      0.40      7008\n",
      "         BPS       0.57      0.70      0.63      7008\n",
      "         CHS       0.58      0.75      0.65      7008\n",
      "         CPP       0.39      0.53      0.45      7008\n",
      "         CTF       0.45      0.54      0.49      7008\n",
      "       CTPID       0.36      0.28      0.32      7007\n",
      "         CTS       0.42      0.28      0.33      7008\n",
      "           N       0.33      0.32      0.32      7007\n",
      "\n",
      "    accuracy                           0.46     56062\n",
      "   macro avg       0.46      0.46      0.45     56062\n",
      "weighted avg       0.46      0.46      0.45     56062\n",
      "\n",
      "\n",
      "LR Confusion Matrix (CV on Training Set):\n",
      "        BPL   BPS   CHS   CPP   CTF  CTPID   CTS     N\n",
      "BPL    2130  3350     5   564   348    133     7   471\n",
      "BPS    1513  4871   233    55   206     50    80     0\n",
      "CHS       0     0  5246   625   218    221   373   325\n",
      "CPP       3    20   708  3736   485    498   439  1119\n",
      "CTF       0     0   687   941  3777    451   401   751\n",
      "CTPID     9    53   553  1349   532   1991   745  1775\n",
      "CTS       5   224   539   486  1971   1667  1938   178\n",
      "N         2     7  1069  1819   783    486   613  2228\n",
      "\n",
      "Ridge Classification Report (CV on Training Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BPL       0.75      0.21      0.33      7008\n",
      "         BPS       0.59      0.87      0.71      7008\n",
      "         CHS       0.34      0.77      0.47      7008\n",
      "         CPP       0.42      0.57      0.49      7008\n",
      "         CTF       0.44      0.47      0.46      7008\n",
      "       CTPID       0.36      0.30      0.33      7007\n",
      "         CTS       0.08      0.02      0.03      7008\n",
      "           N       0.25      0.11      0.15      7007\n",
      "\n",
      "    accuracy                           0.42     56062\n",
      "   macro avg       0.40      0.42      0.37     56062\n",
      "weighted avg       0.40      0.42      0.37     56062\n",
      "\n",
      "\n",
      "Ridge Confusion Matrix (CV on Training Set):\n",
      "        BPL   BPS   CHS   CPP   CTF  CTPID  CTS    N\n",
      "BPL    1467  4230   552   317   178      1   48  215\n",
      "BPS     454  6131    13     3     2    149  256    0\n",
      "CHS       8     1  5398   519   488    217  166  211\n",
      "CPP       8     0  1796  4003   552    163  149  337\n",
      "CTF       9     4  1857   943  3308    421  161  305\n",
      "CTPID     2     1  1952  1157   557   2130  560  648\n",
      "CTS       7     0  1746   872  1146   2416  145  676\n",
      "N        10     2  2616  1611  1227    444  312  785\n",
      "\n",
      "KNN Classification Report (CV on Training Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BPL       0.50      0.41      0.45      7008\n",
      "         BPS       0.57      0.65      0.61      7008\n",
      "         CHS       0.95      0.90      0.92      7008\n",
      "         CPP       0.69      0.78      0.73      7008\n",
      "         CTF       0.65      0.66      0.66      7008\n",
      "       CTPID       0.50      0.57      0.53      7007\n",
      "         CTS       0.87      0.75      0.81      7008\n",
      "           N       0.34      0.32      0.33      7007\n",
      "\n",
      "    accuracy                           0.63     56062\n",
      "   macro avg       0.63      0.63      0.63     56062\n",
      "weighted avg       0.63      0.63      0.63     56062\n",
      "\n",
      "\n",
      "KNN Confusion Matrix (CV on Training Set):\n",
      "        BPL   BPS   CHS   CPP   CTF  CTPID   CTS     N\n",
      "BPL    2847  3395     0    46    37    417     3   263\n",
      "BPS    2447  4551     0     5     3      1     0     1\n",
      "CHS       0     0  6293   226   156     60    82   191\n",
      "CPP      74     0    81  5477   298    320   106   652\n",
      "CTF      26     0    73   481  4655    534   246   993\n",
      "CTPID   171     2    42   272   364   3980   168  2008\n",
      "CTS       9     2    61   479   527    430  5274   226\n",
      "N       156     3   107   924  1132   2257   168  2260\n",
      "\n",
      "SVM Classification Report (CV on Training Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BPL       0.72      0.22      0.33      7008\n",
      "         BPS       0.61      0.92      0.73      7008\n",
      "         CHS       0.92      0.77      0.84      7008\n",
      "         CPP       0.38      0.72      0.49      7008\n",
      "         CTF       0.52      0.62      0.57      7008\n",
      "       CTPID       0.58      0.33      0.42      7007\n",
      "         CTS       0.79      0.26      0.39      7008\n",
      "           N       0.31      0.42      0.35      7007\n",
      "\n",
      "    accuracy                           0.53     56062\n",
      "   macro avg       0.60      0.53      0.52     56062\n",
      "weighted avg       0.60      0.53      0.52     56062\n",
      "\n",
      "\n",
      "SVM Confusion Matrix (CV on Training Set):\n",
      "        BPL   BPS   CHS   CPP   CTF  CTPID   CTS     N\n",
      "BPL    1521  4105     0   627   105     73     1   576\n",
      "BPS     578  6413     0    12     4      0     0     1\n",
      "CHS       1     0  5386   828   364    102    38   289\n",
      "CPP       0     0   105  5061   630    188    26   998\n",
      "CTF       2     0    99  1128  4311    154    65  1249\n",
      "CTPID     3     1    60  1636   429   2308   317  2253\n",
      "CTS       2     0    74  1687  1281    855  1818  1291\n",
      "N         3     0   123  2507  1115    267    47  2945\n",
      "\n",
      "SGD Classification Report (CV on Training Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BPL       0.27      0.30      0.28      7008\n",
      "         BPS       0.55      0.82      0.66      7008\n",
      "         CHS       0.54      0.72      0.62      7008\n",
      "         CPP       0.60      0.52      0.56      7008\n",
      "         CTF       0.32      0.32      0.32      7008\n",
      "       CTPID       0.30      0.28      0.29      7007\n",
      "         CTS       0.24      0.19      0.21      7008\n",
      "           N       0.22      0.11      0.15      7007\n",
      "\n",
      "    accuracy                           0.41     56062\n",
      "   macro avg       0.38      0.41      0.39     56062\n",
      "weighted avg       0.38      0.41      0.39     56062\n",
      "\n",
      "\n",
      "SGD Confusion Matrix (CV on Training Set):\n",
      "        BPL   BPS   CHS   CPP   CTF  CTPID   CTS    N\n",
      "BPL    2087  4002    61    77   278    223   240   40\n",
      "BPS     827  5776   210     0     5     89    70   31\n",
      "CHS     157     7  5041   311   477    246   282  487\n",
      "CPP     650    64   560  3656   702    475   399  502\n",
      "CTF    1115     5   785   558  2211    894   751  689\n",
      "CTPID  1074   102   686   457   979   1960  1281  468\n",
      "CTS     843   426   841   407   929   1740  1304  518\n",
      "N      1104    35  1080   649  1274    889  1197  779\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lks/anaconda3/envs/Project/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lks/anaconda3/envs/Project/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lks/anaconda3/envs/Project/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lks/anaconda3/envs/Project/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/lks/anaconda3/envs/Project/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classification Report (CV on Training Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BPL       0.60      0.38      0.47      7008\n",
      "         BPS       0.62      0.75      0.68      7008\n",
      "         CHS       0.99      0.99      0.99      7008\n",
      "         CPP       0.75      0.78      0.76      7008\n",
      "         CTF       0.82      0.82      0.82      7008\n",
      "       CTPID       0.55      0.76      0.64      7007\n",
      "         CTS       0.99      0.97      0.98      7008\n",
      "           N       0.51      0.38      0.43      7007\n",
      "\n",
      "    accuracy                           0.73     56062\n",
      "   macro avg       0.73      0.73      0.72     56062\n",
      "weighted avg       0.73      0.73      0.72     56062\n",
      "\n",
      "\n",
      "MLP Confusion Matrix (CV on Training Set):\n",
      "        BPL   BPS   CHS   CPP   CTF  CTPID   CTS     N\n",
      "BPL    2674  3232     0    94    13    831     2   162\n",
      "BPS    1737  5257     0     3     5      4     2     0\n",
      "CHS       0     0  6933    18    15      7     6    29\n",
      "CPP       7     0     7  5447   246    574     9   718\n",
      "CTF       0     0     8   237  5734    262    35   732\n",
      "CTPID    23     2     4   527   168   5355    25   903\n",
      "CTS       1     1     7    21    99     38  6808    33\n",
      "N        32     1    22   960   740   2606    16  2630\n",
      "\n",
      "DT Classification Report (CV on Training Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BPL       0.49      0.52      0.50      7008\n",
      "         BPS       0.55      0.51      0.53      7008\n",
      "         CHS       0.94      0.92      0.93      7008\n",
      "         CPP       0.92      0.90      0.91      7008\n",
      "         CTF       0.73      0.72      0.73      7008\n",
      "       CTPID       0.60      0.63      0.61      7007\n",
      "         CTS       0.90      0.88      0.89      7008\n",
      "           N       0.42      0.43      0.42      7007\n",
      "\n",
      "    accuracy                           0.69     56062\n",
      "   macro avg       0.69      0.69      0.69     56062\n",
      "weighted avg       0.69      0.69      0.69     56062\n",
      "\n",
      "\n",
      "DT Confusion Matrix (CV on Training Set):\n",
      "        BPL   BPS   CHS   CPP   CTF  CTPID   CTS     N\n",
      "BPL    3622  2919     0    28    29    234     1   175\n",
      "BPS    3457  3540     0     4     1      2     2     2\n",
      "CHS       1     0  6451    74   125     43    69   245\n",
      "CPP      44     3    39  6340    86    126    50   320\n",
      "CTF      16     1    83    76  5066    263   240  1263\n",
      "CTPID   175     2    46    79   246   4389   169  1901\n",
      "CTS       7     5    46    41   238    214  6191   266\n",
      "N       145     2   186   286  1158   2046   189  2995\n",
      "\n",
      "RF Classification Report (CV on Training Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BPL       0.50      0.41      0.45      7008\n",
      "         BPS       0.54      0.60      0.57      7008\n",
      "         CHS       0.97      0.95      0.96      7008\n",
      "         CPP       0.93      0.93      0.93      7008\n",
      "         CTF       0.76      0.74      0.75      7008\n",
      "       CTPID       0.59      0.62      0.60      7007\n",
      "         CTS       0.91      0.88      0.89      7008\n",
      "           N       0.40      0.43      0.41      7007\n",
      "\n",
      "    accuracy                           0.70     56062\n",
      "   macro avg       0.70      0.70      0.70     56062\n",
      "weighted avg       0.70      0.70      0.70     56062\n",
      "\n",
      "\n",
      "RF Confusion Matrix (CV on Training Set):\n",
      "        BPL   BPS   CHS   CPP   CTF  CTPID   CTS     N\n",
      "BPL    2900  3565     0    25     6    297     1   214\n",
      "BPS    2785  4217     0     0     2      0     2     2\n",
      "CHS       0     0  6654    42    83     41    17   171\n",
      "CPP      12     0    29  6505    37    100    38   287\n",
      "CTF       5     1    28    51  5203    201   170  1349\n",
      "CTPID    80     0    13    56   180   4319   121  2238\n",
      "CTS       0     0    19    46   175    290  6191   287\n",
      "N        56     2    94   258  1166   2130   293  3008\n",
      "\n",
      "GB Classification Report (CV on Training Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BPL       0.87      0.32      0.47      7008\n",
      "         BPS       0.62      0.95      0.75      7008\n",
      "         CHS       0.99      0.92      0.95      7008\n",
      "         CPP       0.89      0.88      0.88      7008\n",
      "         CTF       0.64      0.64      0.64      7008\n",
      "       CTPID       0.62      0.54      0.58      7007\n",
      "         CTS       0.91      0.73      0.81      7008\n",
      "           N       0.42      0.64      0.51      7007\n",
      "\n",
      "    accuracy                           0.70     56062\n",
      "   macro avg       0.75      0.70      0.70     56062\n",
      "weighted avg       0.75      0.70      0.70     56062\n",
      "\n",
      "\n",
      "GB Confusion Matrix (CV on Training Set):\n",
      "        BPL   BPS   CHS   CPP   CTF  CTPID   CTS     N\n",
      "BPL    2226  4050     0    64     4    140     0   524\n",
      "BPS     321  6679     0     2     3      3     0     0\n",
      "CHS       1     0  6434    67   208     51    45   202\n",
      "CPP       1     0    10  6141   131    199    48   478\n",
      "CTF       1     0    20   144  4455    463   170  1755\n",
      "CTPID     3     2    11    94   315   3790    49  2743\n",
      "CTS      10     1    17    93   646    570  5091   580\n",
      "N         2     2    24   266  1177    880   163  4493\n",
      "\n",
      "XGB Classification Report (CV on Training Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BPL       0.72      0.36      0.48      7008\n",
      "         BPS       0.61      0.87      0.72      7008\n",
      "         CHS       1.00      0.99      1.00      7008\n",
      "         CPP       0.98      0.98      0.98      7008\n",
      "         CTF       0.81      0.81      0.81      7008\n",
      "       CTPID       0.72      0.63      0.67      7007\n",
      "         CTS       0.99      0.95      0.97      7008\n",
      "           N       0.53      0.67      0.60      7007\n",
      "\n",
      "    accuracy                           0.78     56062\n",
      "   macro avg       0.80      0.78      0.78     56062\n",
      "weighted avg       0.80      0.78      0.78     56062\n",
      "\n",
      "\n",
      "XGB Confusion Matrix (CV on Training Set):\n",
      "        BPL   BPS   CHS   CPP   CTF  CTPID   CTS     N\n",
      "BPL    2512  3891     0    10     0    228     0   367\n",
      "BPS     915  6088     0     1     0      2     0     2\n",
      "CHS       0     0  6961     1     9      2     2    33\n",
      "CPP       1     0     1  6851    30     24     6    95\n",
      "CTF       2     1     3     9  5653    113    31  1196\n",
      "CTPID    26     1     1    37   174   4407    17  2344\n",
      "CTS       0     1     0    12   142     82  6680    91\n",
      "N        14     2    12    41   953   1237    30  4718\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lks/anaconda3/envs/Project/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:153: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Classification Report (CV on Training Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BPL       0.80      0.32      0.46      7008\n",
      "         BPS       0.61      0.92      0.74      7008\n",
      "         CHS       1.00      0.99      0.99      7008\n",
      "         CPP       0.97      0.95      0.96      7008\n",
      "         CTF       0.81      0.75      0.77      7008\n",
      "       CTPID       0.69      0.59      0.64      7007\n",
      "         CTS       0.99      0.96      0.97      7008\n",
      "           N       0.51      0.69      0.59      7007\n",
      "\n",
      "    accuracy                           0.77     56062\n",
      "   macro avg       0.80      0.77      0.77     56062\n",
      "weighted avg       0.80      0.77      0.77     56062\n",
      "\n",
      "\n",
      "CatBoost Confusion Matrix (CV on Training Set):\n",
      "        BPL   BPS   CHS   CPP   CTF  CTPID   CTS     N\n",
      "BPL    2267  4047     0    23     5    261     0   405\n",
      "BPS     549  6453     0     2     1      1     1     1\n",
      "CHS       0     0  6935     3    22     11     6    31\n",
      "CPP       0     0     8  6653    39    100     6   202\n",
      "CTF       1     0     6    35  5223    270    35  1438\n",
      "CTPID     7     0     1    63   163   4169    13  2591\n",
      "CTS       0     0     7     7   132    103  6708    51\n",
      "N         2     0    12   103   896   1126    12  4856\n",
      "\n",
      "LightGBM Classification Report (CV on Training Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BPL       0.76      0.35      0.48      7008\n",
      "         BPS       0.61      0.90      0.73      7008\n",
      "         CHS       1.00      0.99      1.00      7008\n",
      "         CPP       0.99      0.98      0.99      7008\n",
      "         CTF       0.81      0.80      0.81      7008\n",
      "       CTPID       0.76      0.62      0.68      7007\n",
      "         CTS       0.99      0.96      0.97      7008\n",
      "           N       0.55      0.72      0.62      7007\n",
      "\n",
      "    accuracy                           0.79     56062\n",
      "   macro avg       0.81      0.79      0.78     56062\n",
      "weighted avg       0.81      0.79      0.78     56062\n",
      "\n",
      "\n",
      "LightGBM Confusion Matrix (CV on Training Set):\n",
      "        BPL   BPS   CHS   CPP   CTF  CTPID   CTS     N\n",
      "BPL    2482  3966     0     2     2    191     0   365\n",
      "BPS     711  6292     0     1     0      3     0     1\n",
      "CHS       0     0  6968     1    11      1     0    27\n",
      "CPP       2     0     0  6882    30     11     4    79\n",
      "CTF       1     1     3     5  5610    141    42  1205\n",
      "CTPID    40     2     2    23   158   4332    12  2438\n",
      "CTS       0     0     1    11   159     74  6694    69\n",
      "N        28     2    12    27   927    940    36  5035\n",
      "\n",
      "F1 Scores (Cross-Validation on Training Set):\n",
      "LR: 0.4497\n",
      "Ridge: 0.3705\n",
      "KNN: 0.6298\n",
      "SVM: 0.5161\n",
      "SGD: 0.3857\n",
      "MLP: 0.7206\n",
      "DT: 0.6897\n",
      "RF: 0.6965\n",
      "GB: 0.6984\n",
      "XGB: 0.7774\n",
      "CatBoost: 0.7650\n",
      "LightGBM: 0.7842\n"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    # Statistical Method\n",
    "    \"LR\": LogisticRegression(random_state=42),\n",
    "    \"Ridge\": RidgeClassifier(random_state=42),\n",
    "    # Other Algorithms\n",
    "    \"KNN\": KNeighborsClassifier(n_jobs=-1),\n",
    "    \"SVM\": SVC(random_state=42),\n",
    "    \"SGD\": SGDClassifier(random_state=42),\n",
    "    # Neural Network-Based Model\n",
    "    \"MLP\": MLPClassifier(random_state=42),\n",
    "    # Tree-Based Model\n",
    "    \"DT\": DecisionTreeClassifier(random_state=42),\n",
    "    \"RF\": RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    \"GB\": GradientBoostingClassifier(random_state=42),\n",
    "    \"XGB\": XGBClassifier(random_state=42, n_jobs=-1),\n",
    "    \"CatBoost\": CatBoostClassifier(random_state=42, verbose=0),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42, n_jobs=-1, verbosity=-1),\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Loop through the models\n",
    "f1_scores = {}\n",
    "for model_name, model in models.items():\n",
    "    # Create a pipeline with scaling and classifier\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    # Cross-validated predictions\n",
    "    y_pred_cv = cross_val_predict(pipeline, X_train, y_train, cv=cv, n_jobs=-1)\n",
    "    \n",
    "    # Decode predictions and true labels\n",
    "    y_pred_decoded = label_encoder.inverse_transform(y_pred_cv)\n",
    "    y_true_decoded = label_encoder.inverse_transform(y_train)\n",
    "    \n",
    "    # Classification Report\n",
    "    report = classification_report(y_true_decoded, y_pred_decoded)\n",
    "    print(f\"{model_name} Classification Report (CV on Training Set):\\n{report}\\n\")\n",
    "    \n",
    "    # F1 score (macro average)\n",
    "    f1_score_value = f1_score(y_true_decoded, y_pred_decoded, average='macro')\n",
    "    f1_scores[model_name] = f1_score_value\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_true_decoded, y_pred_decoded)\n",
    "    target_names = label_encoder.classes_\n",
    "    conf_matrix_df = pd.DataFrame(conf_matrix, index=target_names, columns=target_names)\n",
    "    print(f\"{model_name} Confusion Matrix (CV on Training Set):\\n{conf_matrix_df}\\n\")\n",
    "\n",
    "# Print F1 scores\n",
    "print(\"F1 Scores (Cross-Validation on Training Set):\")\n",
    "for model_name, score in f1_scores.items():\n",
    "    print(f\"{model_name}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Classification Report (CV on Training Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         BPL       0.76      0.35      0.48      7008\n",
      "         BPS       0.61      0.90      0.73      7008\n",
      "         CHS       1.00      0.99      1.00      7008\n",
      "         CPP       0.99      0.98      0.99      7008\n",
      "         CTF       0.81      0.80      0.81      7008\n",
      "       CTPID       0.76      0.62      0.68      7007\n",
      "         CTS       0.99      0.96      0.97      7008\n",
      "           N       0.55      0.72      0.62      7007\n",
      "\n",
      "    accuracy                           0.79     56062\n",
      "   macro avg       0.81      0.79      0.78     56062\n",
      "weighted avg       0.81      0.79      0.78     56062\n",
      "\n",
      "\n",
      "LightGBM Confusion Matrix (CV on Training Set):\n",
      "        BPL   BPS   CHS   CPP   CTF  CTPID   CTS     N\n",
      "BPL    2482  3966     0     2     2    191     0   365\n",
      "BPS     711  6292     0     1     0      3     0     1\n",
      "CHS       0     0  6968     1    11      1     0    27\n",
      "CPP       2     0     0  6882    30     11     4    79\n",
      "CTF       1     1     3     5  5610    141    42  1205\n",
      "CTPID    40     2     2    23   158   4332    12  2438\n",
      "CTS       0     0     1    11   159     74  6694    69\n",
      "N        28     2    12    27   927    940    36  5035\n",
      "\n",
      "F1 Scores (Cross-Validation on Training Set):\n",
      "LightGBM: 0.7842\n",
      "Saved!\n"
     ]
    }
   ],
   "source": [
    "# Baseline Model Classification Report Output!\n",
    "\n",
    "models = {\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42, n_jobs=-1, verbosity=-1),\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Loop through the models\n",
    "f1_scores = {}\n",
    "for model_name, model in models.items():\n",
    "    # Create a pipeline with scaling and classifier\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    # Cross-validated predictions\n",
    "    y_pred_cv = cross_val_predict(pipeline, X_train, y_train, cv=cv, n_jobs=-1)\n",
    "    \n",
    "    # Decode predictions and true labels\n",
    "    y_pred_decoded = label_encoder.inverse_transform(y_pred_cv)\n",
    "    y_true_decoded = label_encoder.inverse_transform(y_train)\n",
    "    \n",
    "    # Classification Report\n",
    "    report = classification_report(y_true_decoded, y_pred_decoded)\n",
    "    print(f\"{model_name} Classification Report (CV on Training Set):\\n{report}\\n\")\n",
    "    \n",
    "    # F1 score (macro average)\n",
    "    f1_score_value = f1_score(y_true_decoded, y_pred_decoded, average='macro')\n",
    "    f1_scores[model_name] = f1_score_value\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_true_decoded, y_pred_decoded)\n",
    "    target_names = label_encoder.classes_\n",
    "    conf_matrix_df = pd.DataFrame(conf_matrix, index=target_names, columns=target_names)\n",
    "    print(f\"{model_name} Confusion Matrix (CV on Training Set):\\n{conf_matrix_df}\\n\")\n",
    "\n",
    "# Print F1 scores\n",
    "print(\"F1 Scores (Cross-Validation on Training Set):\")\n",
    "for model_name, score in f1_scores.items():\n",
    "    print(f\"{model_name}: {score:.4f}\")\n",
    "\n",
    "# Convert classification report to DataFrame\n",
    "report_dict = classification_report(y_true_decoded, y_pred_decoded, output_dict=True)\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "\n",
    "# Save to Excel\n",
    "with pd.ExcelWriter(\"classification_report_Baseline(CV).xlsx\") as writer:\n",
    "    report_df.to_excel(writer, sheet_name=\"Classification Report\")\n",
    "    conf_matrix_df.to_excel(writer, sheet_name=\"Confusion Matrix\")\n",
    "\n",
    "print(\"Saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-Parameter for Optimal Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1944 candidates, totalling 9720 fits\n",
      "Best Parameters: {'model__colsample_bytree': 1.0, 'model__learning_rate': 0.1, 'model__min_child_samples': 20, 'model__n_estimators': 100, 'model__num_leaves': 31, 'model__reg_alpha': 0.0, 'model__reg_lambda': 0.0, 'model__subsample': 0.6}\n",
      "Best Cross-Validation Score: 0.793907369770017\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model__colsample_bytree</th>\n",
       "      <th>param_model__learning_rate</th>\n",
       "      <th>param_model__min_child_samples</th>\n",
       "      <th>param_model__n_estimators</th>\n",
       "      <th>param_model__num_leaves</th>\n",
       "      <th>param_model__reg_alpha</th>\n",
       "      <th>...</th>\n",
       "      <th>param_model__subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>30.352405</td>\n",
       "      <td>1.452365</td>\n",
       "      <td>0.309054</td>\n",
       "      <td>0.008984</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'model__colsample_bytree': 1.0, 'model__learn...</td>\n",
       "      <td>0.785121</td>\n",
       "      <td>0.795698</td>\n",
       "      <td>0.792991</td>\n",
       "      <td>0.795729</td>\n",
       "      <td>0.799997</td>\n",
       "      <td>0.793907</td>\n",
       "      <td>0.004933</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>30.352870</td>\n",
       "      <td>0.958223</td>\n",
       "      <td>0.309782</td>\n",
       "      <td>0.006166</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'model__colsample_bytree': 1.0, 'model__learn...</td>\n",
       "      <td>0.785121</td>\n",
       "      <td>0.795698</td>\n",
       "      <td>0.792991</td>\n",
       "      <td>0.795729</td>\n",
       "      <td>0.799997</td>\n",
       "      <td>0.793907</td>\n",
       "      <td>0.004933</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>30.491282</td>\n",
       "      <td>1.078479</td>\n",
       "      <td>0.313603</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'model__colsample_bytree': 1.0, 'model__learn...</td>\n",
       "      <td>0.785121</td>\n",
       "      <td>0.795698</td>\n",
       "      <td>0.792991</td>\n",
       "      <td>0.795729</td>\n",
       "      <td>0.799997</td>\n",
       "      <td>0.793907</td>\n",
       "      <td>0.004933</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>31.192203</td>\n",
       "      <td>0.272369</td>\n",
       "      <td>0.306379</td>\n",
       "      <td>0.009647</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'model__colsample_bytree': 1.0, 'model__learn...</td>\n",
       "      <td>0.785718</td>\n",
       "      <td>0.795699</td>\n",
       "      <td>0.794687</td>\n",
       "      <td>0.795744</td>\n",
       "      <td>0.796635</td>\n",
       "      <td>0.793697</td>\n",
       "      <td>0.004037</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>30.776328</td>\n",
       "      <td>0.670176</td>\n",
       "      <td>0.298626</td>\n",
       "      <td>0.007173</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'model__colsample_bytree': 1.0, 'model__learn...</td>\n",
       "      <td>0.785718</td>\n",
       "      <td>0.795699</td>\n",
       "      <td>0.794687</td>\n",
       "      <td>0.795744</td>\n",
       "      <td>0.796635</td>\n",
       "      <td>0.793697</td>\n",
       "      <td>0.004037</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>124.280025</td>\n",
       "      <td>3.731716</td>\n",
       "      <td>2.832744</td>\n",
       "      <td>0.035685</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>30</td>\n",
       "      <td>300</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'model__colsample_bytree': 0.8, 'model__learn...</td>\n",
       "      <td>0.770101</td>\n",
       "      <td>0.770286</td>\n",
       "      <td>0.773962</td>\n",
       "      <td>0.776778</td>\n",
       "      <td>0.774352</td>\n",
       "      <td>0.773096</td>\n",
       "      <td>0.002559</td>\n",
       "      <td>1939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>125.214385</td>\n",
       "      <td>2.718746</td>\n",
       "      <td>2.791427</td>\n",
       "      <td>0.016798</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>30</td>\n",
       "      <td>300</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'model__colsample_bytree': 0.8, 'model__learn...</td>\n",
       "      <td>0.770101</td>\n",
       "      <td>0.770286</td>\n",
       "      <td>0.773962</td>\n",
       "      <td>0.776778</td>\n",
       "      <td>0.774352</td>\n",
       "      <td>0.773096</td>\n",
       "      <td>0.002559</td>\n",
       "      <td>1939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>115.348016</td>\n",
       "      <td>3.764505</td>\n",
       "      <td>3.531481</td>\n",
       "      <td>1.438094</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>30</td>\n",
       "      <td>300</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'model__colsample_bytree': 0.8, 'model__learn...</td>\n",
       "      <td>0.771811</td>\n",
       "      <td>0.768889</td>\n",
       "      <td>0.774200</td>\n",
       "      <td>0.776798</td>\n",
       "      <td>0.773344</td>\n",
       "      <td>0.773008</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>1942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>114.455811</td>\n",
       "      <td>2.763382</td>\n",
       "      <td>2.328521</td>\n",
       "      <td>0.010040</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>30</td>\n",
       "      <td>300</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'model__colsample_bytree': 0.8, 'model__learn...</td>\n",
       "      <td>0.771811</td>\n",
       "      <td>0.768889</td>\n",
       "      <td>0.774200</td>\n",
       "      <td>0.776798</td>\n",
       "      <td>0.773344</td>\n",
       "      <td>0.773008</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>1942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>114.923548</td>\n",
       "      <td>1.704021</td>\n",
       "      <td>3.694617</td>\n",
       "      <td>1.682202</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>30</td>\n",
       "      <td>300</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'model__colsample_bytree': 0.8, 'model__learn...</td>\n",
       "      <td>0.771811</td>\n",
       "      <td>0.768889</td>\n",
       "      <td>0.774200</td>\n",
       "      <td>0.776798</td>\n",
       "      <td>0.773344</td>\n",
       "      <td>0.773008</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>1942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1944 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1404      30.352405      1.452365         0.309054        0.008984   \n",
       "1406      30.352870      0.958223         0.309782        0.006166   \n",
       "1405      30.491282      1.078479         0.313603        0.002032   \n",
       "1306      31.192203      0.272369         0.306379        0.009647   \n",
       "1307      30.776328      0.670176         0.298626        0.007173   \n",
       "...             ...           ...              ...             ...   \n",
       "1287     124.280025      3.731716         2.832744        0.035685   \n",
       "1289     125.214385      2.718746         2.791427        0.016798   \n",
       "1285     115.348016      3.764505         3.531481        1.438094   \n",
       "1286     114.455811      2.763382         2.328521        0.010040   \n",
       "1284     114.923548      1.704021         3.694617        1.682202   \n",
       "\n",
       "      param_model__colsample_bytree  param_model__learning_rate  \\\n",
       "1404                            1.0                         0.1   \n",
       "1406                            1.0                         0.1   \n",
       "1405                            1.0                         0.1   \n",
       "1306                            1.0                         0.1   \n",
       "1307                            1.0                         0.1   \n",
       "...                             ...                         ...   \n",
       "1287                            0.8                         0.2   \n",
       "1289                            0.8                         0.2   \n",
       "1285                            0.8                         0.2   \n",
       "1286                            0.8                         0.2   \n",
       "1284                            0.8                         0.2   \n",
       "\n",
       "      param_model__min_child_samples  param_model__n_estimators  \\\n",
       "1404                              20                        100   \n",
       "1406                              20                        100   \n",
       "1405                              20                        100   \n",
       "1306                              10                        100   \n",
       "1307                              10                        100   \n",
       "...                              ...                        ...   \n",
       "1287                              30                        300   \n",
       "1289                              30                        300   \n",
       "1285                              30                        300   \n",
       "1286                              30                        300   \n",
       "1284                              30                        300   \n",
       "\n",
       "      param_model__num_leaves  param_model__reg_alpha  ...  \\\n",
       "1404                       31                     0.0  ...   \n",
       "1406                       31                     0.0  ...   \n",
       "1405                       31                     0.0  ...   \n",
       "1306                       31                     0.3  ...   \n",
       "1307                       31                     0.3  ...   \n",
       "...                       ...                     ...  ...   \n",
       "1287                      100                     0.0  ...   \n",
       "1289                      100                     0.0  ...   \n",
       "1285                      100                     0.0  ...   \n",
       "1286                      100                     0.0  ...   \n",
       "1284                      100                     0.0  ...   \n",
       "\n",
       "      param_model__subsample  \\\n",
       "1404                     0.6   \n",
       "1406                     1.0   \n",
       "1405                     0.8   \n",
       "1306                     0.8   \n",
       "1307                     1.0   \n",
       "...                      ...   \n",
       "1287                     0.6   \n",
       "1289                     1.0   \n",
       "1285                     0.8   \n",
       "1286                     1.0   \n",
       "1284                     0.6   \n",
       "\n",
       "                                                 params split0_test_score  \\\n",
       "1404  {'model__colsample_bytree': 1.0, 'model__learn...          0.785121   \n",
       "1406  {'model__colsample_bytree': 1.0, 'model__learn...          0.785121   \n",
       "1405  {'model__colsample_bytree': 1.0, 'model__learn...          0.785121   \n",
       "1306  {'model__colsample_bytree': 1.0, 'model__learn...          0.785718   \n",
       "1307  {'model__colsample_bytree': 1.0, 'model__learn...          0.785718   \n",
       "...                                                 ...               ...   \n",
       "1287  {'model__colsample_bytree': 0.8, 'model__learn...          0.770101   \n",
       "1289  {'model__colsample_bytree': 0.8, 'model__learn...          0.770101   \n",
       "1285  {'model__colsample_bytree': 0.8, 'model__learn...          0.771811   \n",
       "1286  {'model__colsample_bytree': 0.8, 'model__learn...          0.771811   \n",
       "1284  {'model__colsample_bytree': 0.8, 'model__learn...          0.771811   \n",
       "\n",
       "      split1_test_score  split2_test_score  split3_test_score  \\\n",
       "1404           0.795698           0.792991           0.795729   \n",
       "1406           0.795698           0.792991           0.795729   \n",
       "1405           0.795698           0.792991           0.795729   \n",
       "1306           0.795699           0.794687           0.795744   \n",
       "1307           0.795699           0.794687           0.795744   \n",
       "...                 ...                ...                ...   \n",
       "1287           0.770286           0.773962           0.776778   \n",
       "1289           0.770286           0.773962           0.776778   \n",
       "1285           0.768889           0.774200           0.776798   \n",
       "1286           0.768889           0.774200           0.776798   \n",
       "1284           0.768889           0.774200           0.776798   \n",
       "\n",
       "      split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "1404           0.799997         0.793907        0.004933                1  \n",
       "1406           0.799997         0.793907        0.004933                1  \n",
       "1405           0.799997         0.793907        0.004933                1  \n",
       "1306           0.796635         0.793697        0.004037                4  \n",
       "1307           0.796635         0.793697        0.004037                4  \n",
       "...                 ...              ...             ...              ...  \n",
       "1287           0.774352         0.773096        0.002559             1939  \n",
       "1289           0.774352         0.773096        0.002559             1939  \n",
       "1285           0.773344         0.773008        0.002619             1942  \n",
       "1286           0.773344         0.773008        0.002619             1942  \n",
       "1284           0.773344         0.773008        0.002619             1942  \n",
       "\n",
       "[1944 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_model = LGBMClassifier(random_state=42, n_jobs=-1, verbosity=-1)\n",
    "\n",
    "# pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', lgbm_model)\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'model__num_leaves': [31, 50, 100],  # Default: 31\n",
    "    'model__learning_rate': [0.1, 0.2],  # Default: 0.1\n",
    "    'model__n_estimators': [100, 200, 300],  # Default: 100\n",
    "    'model__min_child_samples': [10, 20, 30],  # Default: 20\n",
    "    'model__subsample': [0.6, 0.8, 1.0],  # Default: 1.0\n",
    "    'model__colsample_bytree': [0.6, 0.8, 1.0],  # Default: 1.0\n",
    "    'model__reg_alpha': [0.0, 0.3],  # Default: 0.0\n",
    "    'model__reg_lambda': [0.0, 0.3],  # Default: 0.0\n",
    "}\n",
    "\n",
    "# StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# GridSearchCV with pipeline\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, scoring='f1_macro', cv=skf, n_jobs=-1, verbose=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Cross-Validation Score: {grid_search.best_score_}\")\n",
    "\n",
    "# GridSearch Results in Descending Order\n",
    "cv_results = grid_search.cv_results_\n",
    "cv_results_df = pd.DataFrame(cv_results)\n",
    "cv_results_df_sorted = cv_results_df.sort_values(by='mean_test_score', ascending=False)\n",
    "\n",
    "cv_results_df_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned Optimal Baseline Model for Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score       support\n",
      "BPL            0.743652  0.351027  0.476929   1752.000000\n",
      "BPS            0.605645  0.881849  0.718104   1752.000000\n",
      "CHS            0.997714  0.996575  0.997144   1752.000000\n",
      "CPP            0.987371  0.981735  0.984545   1752.000000\n",
      "CTF            0.859514  0.827626  0.843268   1752.000000\n",
      "CTPID          0.791170  0.644406  0.710286   1752.000000\n",
      "CTS            0.987356  0.980594  0.983963   1752.000000\n",
      "N              0.562827  0.736301  0.637982   1752.000000\n",
      "accuracy       0.800014  0.800014  0.800014      0.800014\n",
      "macro avg      0.816906  0.800014  0.794028  14016.000000\n",
      "weighted avg   0.816906  0.800014  0.794028  14016.000000\n",
      "\n",
      "Confusion Matrix:\n",
      "       BPL   BPS   CHS   CPP   CTF  CTPID   CTS     N\n",
      "BPL    615  1003     0     1     1     49     1    82\n",
      "BPS    206  1545     0     0     0      0     1     0\n",
      "CHS      0     0  1746     0     0      1     0     5\n",
      "CPP      0     0     0  1720     2      1     2    27\n",
      "CTF      0     0     0     3  1450     17     7   275\n",
      "CTPID    3     1     0     4    18   1129     0   597\n",
      "CTS      0     0     0     0    17      1  1718    16\n",
      "N        3     2     4    14   199    229    11  1290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model with hyper-parameter\n",
    "paras = {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'min_child_samples': 20, 'n_estimators': 100, 'num_leaves': 31, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 0.6}\n",
    "lgbm_model = LGBMClassifier(random_state=42, n_jobs=-1, verbosity=-1, **paras)\n",
    "\n",
    "# pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # StandardScaler for feature scaling\n",
    "    ('model', lgbm_model)           # LGBMClassifier model\n",
    "])\n",
    "\n",
    "# Train on training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation on testing dataaet\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Classification Report\n",
    "y_test_pred_decoded = label_encoder.inverse_transform(y_test_pred)\n",
    "y_test_decoded = label_encoder.inverse_transform(y_test)\n",
    "report = classification_report(y_test_decoded, y_test_pred_decoded, target_names=label_encoder.classes_, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "print(f\"Classification Report:\\n{report_df}\\n\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test_decoded, y_test_pred_decoded)\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=label_encoder.classes_, columns=label_encoder.classes_)\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix_df}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seved!\n"
     ]
    }
   ],
   "source": [
    "with pd.ExcelWriter(\"classification_report_Baseline.xlsx\") as writer:\n",
    "    report_df.to_excel(writer, sheet_name=\"Classification Report\")\n",
    "    conf_matrix_df.to_excel(writer, sheet_name=\"Confusion Matrix\")\n",
    "\n",
    "print(\"Seved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
